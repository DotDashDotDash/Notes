## 计算机操作系统相关知识

> ### 存储板块

1. **常见的串行访问存储器**

```markdown
串行访问存储器是对存储单元进行读写的时候，需要按照其物理位置的先后顺序寻址
串行访问存储器包括“顺序存取存储器(磁带)”和“直接存取存储器(磁盘)”
```

2. **顺序存取存储器和直接存取存储器以及RAM之间的区别**

```markdown
顺序存取存储器只能按照顺序存取
RAM可以按照随机访问任何一个单元
直接存取存储器介于两者之间，寻取信息的时候先寻找整个存储器的某个小区域(例如磁道)，再在小区域内部查找
```

3. **什么是相联存储器？**

```markdown
其基本原理是把存储单元所存内容的某一部分作为检索项去检索该存储器，并将存储器中与该检索项符合的存储单元内容读出或者写入
```

4. **操作系统程序保存在哪里？**

```markdown
操作系统程序保存在硬盘上，首先要先将其引导到主存中，而引导程序通常放在ROM中
而程序运行时需要读写操作，因此应该采用RAM
```

5. **双端口RAM的读写冲突**

```markdown
双端口RAM并不是对同一个内存地址单元进行操作的时候都会发生冲突
1. A读取地址M，B写地址M，会冲突
2. A写地址M，B写地址M，会冲突
3. A读地址M，B读地址M，会冲突
```

6. **高位交叉编址和低位交叉编址谁更好的利用了局部性原理？**

```markdown
看起来高位交叉编址的存储器内容连续存放好像更加满足程序的局部性原理，但是其实是低位交叉编址更加满足！！！！！！
高位交叉编址并没有提高存储器的带宽，相反低位交叉编址虽然不连续，但是连续读取的带宽变大了，更像是为了满足程序局部性原理
而设计的产物
```

7. **有关低位交叉编址的误区！！！！**

```markdown
Pre: 假设一个四体低位交叉存储器，每个模块的容量是64K × 32位，存取周期为200ns，总线周期为50ns

说法：在50ns内，每个模块能向CPU提供32位信息？
分析：这种说法是错误的，是在200ns内，整个存储器能向CPU提供128位信息，但是每一个存储体仍然需要200ns才能向整个存储器提供32
	 位信息
```

8. **Cache写策略**

```markdown
1. Cache写命中的时候
	(1) 全写法：CPU将数据同时写回Cache和主存
	(2) 写回法：CPU只写入Cache不写入主存，等到换出Cache块的时候才写入主存，需要设置脏位
2. Cache写不命中的时候
	(1) 写分配法：加载主存中的块到Cache中，然后更新这个Cache，试图利用空间局部性，但是每一次不命中都要替换
	(2) 非写分配法：只写主存，不调块

非写分配法通常和全写法合用，写分配法通常和写回法合用
```

9. **加快地址转换的快表TLB**

```markdown
TLB是由高速缓冲存储器构成，其不是放在内存当中，而是放在专门的存储器
TLB的内容基本包含3个部分：Tag、Valid、实页号
```

10. **虚拟地址VA和物理地址PA之间的关系(重要)**

```markdown
//2018年王道真题
Q: 假设计算机按照字节编址，虚拟地址空间大小为16MB，物理地址大小为1MB，页面大小为4KB，Cache采用直接映射方式，共8行，主存
   和Cache之间交换的块大小为32B。判断虚拟地址位数，物理地址位数，虚页号位数，页框号位数，TLB中的tag位数，Cache中的Tag位数

1. 虚拟地址空间大小为16MB，因此虚拟地址位数为24位
2. 物理地址空间大小为1MB，因此物理地址位数为20位
3. 页面大小为4KB，即12位，因此VAP位数为24-12=12位，PAP位数为20-12=8位
4. PA为24位，页大小为4KB，因此TLB中的tag标记为共24-12=12位
5. PA的组成为：Tag,Index,Offset，其中块大小为32B，Offset共5位，直接映射共8行，Index共3位，故Tag=20-5-3=12位

补：若TLB还要组相联，还要从虚页号VAP中划分
```

11. **存取周期和存取时间**

```markdown
存取时间表示完成一次操作的时间，存取周期不仅包含操作时间还包含操作之后恢复线路的时间
存取周期=存取时间+恢复时间
```

12. **主存和Cache之间的调度是由硬件还是软件完成？**

```markdown
纯硬件
```

13. **用户源程序到内存中可执行程序的过程**

```markdown
1. 编译：将用户源代码编译成若干目标模块
2. 链接：将目标模块与所需的库函数链接在一起，形成完整的装入模块
3. 装入：将装入模块装入到内存中运行

(1) 在链接阶段
	a. 静态链接：程序运行之前，就链接成一个完整的模块，之后不再分开
	b. 装入时动态链接：装入内存时，边装入边链接
	c. 运行时动态链接：程序需要执行该目标模块时才链接。便于修改和更新，实现对目标模块的共享
(2) 在装入阶段
	a. 绝对装入：在“编译”时就知道程序将驻留内存的某个区域，“编译程序产生绝对地址的目标代码”，程序的逻辑地址与物理地址完全
	   相同
	b. 静态重定位装入：一个作业的地址由逻辑地址加上这个作业的起始地址，作业在装入的时候，必须分配它要求的全部内存空间，若没有
	   足够的内存，则不能装入这个作业。此外作业一旦进入内存，整个运行期间就不能在内存中移动，也不能再申请内存空间
	c. 动态重定位装入：程序装入内存时并不进行地址转换，而当运行时才进行地址转换，而且程序不需要被分配到连续的内存之中，还可以
	   根据需要动态申请分配内存。“这种方式需要一个重定位寄存器”
```

14. **分段存储管理如何实现段的共享和保护？**

```markdown
1. 段的共享
	(1) 段的共享是通过两个作业的段表中相应的表项指向被共享的段的一个物理副本实现的
	(2) 若进程P1和P2共享段S，那么下列说法中错误的是:
		a. P1和P2在物理内存中仅保留一份段S的内容(√)
		b. 段S在P1和P2中应该有相同的段号(×)
			解析：段S在P1和P2中的使用位置可能不同，因此逻辑段号可能不同，但是段表中的物理段号是唯一的
		c. P1和P2共享段S在段表中的段表项(√)
		d. P1和P2都不再使用段S时才会回收段S所占的内存空间(√)
```

15. **区分临界资源，临界区和内核临界区**

```markdown
1. 临界资源：临界资源指的是一次只能被一个进程所用的资源。许多物理设备都是临界资源，许多变量和数据结构也属于临界资源。(注意区分共享和互斥访问，一个资源可以被共享，但是需要互斥访问也属于临界资源)
2. 临界区：临界区是指访问临界资源的那段代码
3. 内核临界区：访问内核临界资源的代码

注意：处于临界区的进程可以被调度，但是处于内核临界区的进程不能被调度
```

16. **同步机制应该遵循的准则**

```markdown
1. 空闲让进
2. 忙则等待
3. 有限等待
4. 让权等待
```

17. **实现临界区互斥的方法**

```markdown
1. 软件实现方法：单标志法、双标志先检查法，双标志后检查法、Peterson法
```

```c++
//单标志法
Process1(){
    while(turn != 0);	//检查是否允许P1进入
    critical section;	//临界区
    turn = 1;			//允许P2进入
    remainder section;	//剩余区
}

Process2(){
    while(turn != 1);	//检查是否允许P2进入
    critical section;	//临界区
    turn = 0;			//允许P1进入
    remainder section;	//剩余区
}

//注：单标志法违背了“空闲让进”的原则，P1的再次进入需要P2进行响应的标志修改，连续的P1执行不能实现
```

```c++
//双标志先检查法

int flag[2];	//flag[i]=false说明进程i没有进入临界区

Process1(){
    while(flag[1]);		//如果P2已经在临界区，循环等待
    flag[0] = true;		//P1进入
    critical section;	//临界区
    flag[0] = false;	//P1退出
    remainder section;	//剩余区
}

Process2(){
    while(flag[0]);		//如果P1已经在临界区，循环等待
    flag[1] = true;		//P2进入
    critical section;	//临界区
    flag[1] = false;	//P2退出
    remainder section;	//剩余区
}

//注：假如P1和P2同时进入，发现双方都可以进入临界区，那么会违背“忙则等待”原则
```

```c++
//双标志后检查法

int flag[2];	//flag[i]=false说明进程i没有进入临界区

Process1(){
    flag[0] = true;		//P1要进入
    while(flag[1]);		//判断P2有没有进入
    critical section;	//临界区
    flag[0] = false;	//P1退出
    remainder section;	//剩余区
}

Process2(){
    flag[1] = true;		//P2要进入
    while(flag[0]);		//检查P1有没有进入
    critical section;	//临界区
    flag[1] = false;	//P2退出
    remainder section;	//剩余区
}

//注：假如P1和P2同时到达，同时设置flag，导致两个进程均无限等待，违背了“空闲让进”的原则，会产生“饥饿”
```

```c++
//Peterson算法
int turn = -1;	//turn=i表示不允许进程i进入
int flag[2];

Process1(){
    flag[0] = true;					//P1进入
    turn = 1;						//禁止P2进入
    while(flag[1] && turn == 1);	//P2已经进入但是不允许P2进入
    critical section;				//临界区
    flag[0] = false;				//P1退出
    remainder section;				//剩余区
}

Process2(){
    flag[1] = true;					//P2进入
    turn = 0;						//不允许P1进入
    while(flag[0] && turn == 0);	//P1已经进入但是不允许P1进入
    critical section;				//临界区
    flag[1] = false;				//P2退出
    remainder section;				//剩余区
}

//Condition1: 假如P1略晚于P2，flag[0]=true,flag[1]=true,turn=1，此时P1等待，P2执行完之后，P1执行
//Condition2: 假如P2略晚于P1，P1先执行，之后P2执行
//Condition3: 假如连续的两个P1，此时P1可以顺序执行
//Condition4: 假如连续的两个P2，此时P2可以顺序执行
//Condition5: 顺序是P1,P2,P1，在Condition2完成之后，flag[0]=flag[1]=false,turn=0，此时P1可以顺利执行
///备注：Peterson相较于双标志法的改进就是通过turn来解决了“饥饿”问题
```

```markdown
2. 硬件实现方法：
	(1) 中断屏蔽法：关中断；临界区；开中断
	(2) 硬件指令方法: 
		a. TestAndSet，此操作是原子操作，执行该代码的时候不允许被中断，其功能就是在读出指定标志之后把该标志
		设置为“真”
		b. Swap，交换两个字(字节)的内容
    上述的硬件实现方法是抽象的，底层是通过“硬件逻辑”直接实现的，硬件实现的好处就是适用于任意数目的进程，可以支持多个临界区，
    只需要为每一个临界区设置一个布尔变量。其缺点也很明显，进程进入临界区需要耗费处理机资源，不能实现让权等待，从进程中随机
    选择一个进入临界区，有的进程可能一直都选不上，从而导致“饥饿”
3. 信号量：
	(1) 整型信号量：通过单一的整型元素，再结合wait(), signal()实现同步
		注：wait操作中，只要S<=0，就会不断的测试。因此，该机制并没有遵循“让权等待”，而是让进程处于“忙等“
	(2) 记录型信号量：用一个value代表资源的数目，再增加一个链表L，链接处于等待的进程。
		注：很重要！！！！！！！！！！！！！！！！！
		   a. wait操作中，S.value<0，就会添加到链表中，S.value<=0不添加
		   b. signal操作中，S.value<=0，就会唤醒一个进程(为什么？？？)：signal操作中，S.value在自增之后仍为0，说明
		   	  链表中还有被阻塞的进程，这个时候需要wakeup唤醒
```

18. **谈谈管程**

```markdown
1. 管程的名称
2. 局部于管程内部的共享数据结构的说明
3. 对该数据结构进行操作的一组过程
4. 对局部于管程内部的共享数据设置初始值的语句
```

```c++
monitor A{			 //定义了管程的名称
    Source S;		 //共享的数据结构
    Condition x;	 //因为什么Condition而阻塞进程
    init(){ S = 5; } //对共享数据设置初值 
    
    sub(){
        if(S <= 0)
            x.wait();
        S--;
    }
    
    add(){
        S++;
        if(x.has())
            x.signal();
    }
}
```

19. **实现读写公平的读写问题**

```c++
int rcount = 0;			//用于记录读者的数目，读者为0时才可以写
semaphore mutex = 1;	//用于对count的互斥访问
semaphore rw = 1;		//写锁
semaphore w;			//实现写优先

writer(){
    while(1){
        P(w);			//首先先占这这把锁，当读者为0的时候就可以继续获取写锁
        P(rw);			//获取写锁
		writing;
        V(rw);			//释放写锁
        V(w);			//释放写优先
    }
}

reader(){
    while(1){
        P(w);			//无写请求的时候进入后续代码
        P(mutex);		//互斥访问rcount
        if(rcount == 0)
            P(rw);		//当没有读者，把写锁占了，一般这个是第一个reader的任务
       	rcount++;
        V(mutex);
        V(w);			//释放写优先
        reading;		//开始读
        P(mutex);		//互斥访问rcount;
        rcount--;		//读者减1
        V(mutex);	
        if(rcount == 0)
            V(rw);		//没有读者，释放写锁
        V(mutex);		
    }
}
```

