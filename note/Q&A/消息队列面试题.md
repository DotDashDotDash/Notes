# 消息队列面试汇总

### 1. 为什么要使用消息队列

* **解耦**: 将消息放置到队列当中，需要的时候自己去拿
* **异步**: 一个程序全部都以同步的方式运行，代价太大
* **削峰**: 没有消息队列，所有的消息全部都砸到数据库，并发量太大

### 2. 使用了消息队列的弊端

很多人被这个问题给问懵了，消息队列不是高大上的东西吗，为什么还会有弊端(手动狗头)

这是必然的，从哲学的角度来说，事物具有两面性，MQ也是如此，既然引入了MQ，就必须承但它可能会带来的后果

* **系统可用性降低**: 如果你的MQ挂了，你的系统也有大概率挂了
* **系统复杂度升高**: 既然引入了MQ，就必须考虑MQ的一系列问题(下面会讲)

### 3. 如何保证分布式系统的高可用性

* **RokcetMQ**: 主从模式，基本配置为多master，多slave，主从同步双写，主从异步复制模式
* **Kafka**: 一个Producer Group，一个Consumer Group，一个ZooKeeper集群，一个Broker集群，基本流程如下:

```markdown
1. Producer和NameServer集群中的一个节点随机创建TCP长连接
2. 找到与NameServer对应的Topic
3. 与Topic对应的Broker创建长连接，且定时发送心跳
4. Producer向Broker push消息
5. Consumer pull消费(也可以push)
```

### 4. RabbitMQ, RockerMQ, Kafka都是如何保证消息不被重复消费

**分析：这个问题其实换一种问法就是，如何保证消息队列的幂等性？**这个问题可以认为是消息队列领域的基本问题。换句话来说，是在考察你的设计能力，这个问题的回答可以根据具体的业务场景来答，没有固定的答案。

**回答：先来说一下为什么会造成重复消费？**
其实无论是哪种消息队列，造成重复消费原因其实都是类似的。正常情况下，消费者在消费消息的时候，消费完毕后，会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。只是不同的消息队列发出的确认消息形式不同，例如RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka实际上有个offset的概念，简单说一下，就是每一个消息都有一个offset，kafka消费过消息后，需要提交offset，让消息队列知道自己已经消费过了

### 5. 造成消息重复消费的原因是什么

就是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者

**从业务场景的角度来说，如果要你设计避免重复消费问题**

* **比如数据库的insert操作**: 设置主键，重复消费会导致主键冲突
* **比如redis的set**: 天然幂等，不存在重复消费问题
* **最暴力的方法，自己设置一个消费记录，利用redis的`<id, message>`记录消费过的**

### 6. 如何保证消费的可靠性传输

**1. 生产者弄丢消息**

从生产者弄丢数据这个角度来看，RabbitMQ提供transaction和confirm模式来确保生产者不丢消息。

transaction机制就是说，发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()）,如果发送成功则提交事务（channel.txCommit()）。

然而，这种方式有个缺点：吞吐量下降。因为，按照经验，生产上用confirm模式的居多。一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了。如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。处理Ack和Nack的代码如下所示:

```java
channel.addConfirmListener(new ConfirmListener() {  
      @Override  
      public void handleNack(long deliveryTag, boolean multiple) throws IOException {  
            System.out.println("nack: deliveryTag = "+deliveryTag+" multiple: "+multiple);  
      }  
                
      @Override  
      public void handleAck(long deliveryTag, boolean multiple) throws IOException {  
            System.out.println("ack: deliveryTag = "+deliveryTag+" multiple: "+multiple);  
      }  
});  
```

**2. 消息队列弄丢消息**

处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。

那么如何持久化呢，这里顺便说一下吧，其实也很容易，就下面两步

* 将queue的持久化标识durable设置为true,则代表是一个持久的队列
* 发送消息的时候将deliveryMode=2

这样设置以后，即使rabbitMQ挂了，重启后也能恢复数据

**3. 消费者弄丢消息**

消费者丢数据一般是因为采用了自动确认消息模式。这种模式下，消费者会自动确认收到信息。这时rabbitMQ会立即将消息删除，这种情况下，如果消费者出现异常而未能处理消息，就会丢失该消息。

**至于解决方案，采用手动确认消息即可**

**分析：其实并非所有的公司都有这种业务需求，但是还是对这个问题要有所复习**

**回答:**针对这个问题，通过某种算法，将需要保持先后顺序的消息放到同一个消息队列中(kafka中就是partition,rabbitMq中就是queue)。然后只用一个消费者去消费该队列。
有的人会问:那如果为了吞吐量，有多个消费者去消费怎么办？

这个问题，没有固定回答的套路。比如我们有一个微博的操作，发微博、写评论、删除微博，这三个异步操作。如果是这样一个业务场景，那只要重试就行。比如你一个消费者先执行了写评论的操作，但是这时候，微博都还没发，写评论一定是失败的，等一段时间。等另一个消费者，先执行写评论的操作后，再执行，就可以成功。

总之，针对这个问题，我的观点是保证入队有序就行，出队以后的顺序交给消费者自己去保证，没有固定套路